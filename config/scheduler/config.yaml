cyclePeriod: 5s
schedulePeriod: 1s
maxSchedulingDuration: 5m
executorTimeout: 1h
databaseFetchSize: 1000
pulsarSendTimeout: 5s
internedStringsCacheSize: 100000
queueRefreshPeriod: 10s
metrics:
  port: 9009
  jobStateMetricsResetInterval: 12h
  refreshInterval: 3s
  trackedResourceNames:
    - "cpu"
    - "memory"
    - "ephemeral-storage"
    - "nvidia.com/gpu"
pulsar:
  URL: "pulsar://localhost:6650"
  jobsetEventsTopic: "events"
  maxConnectionsPerBroker: 1
  compressionType: zlib
  compressionLevel: faster
  maxAllowedEventsPerMessage: 1000
  maxAllowedMessageSize: 4194304 #4Mi
  sendTimeout: 5s
armadaApi:
  armadaUrl: "localhost:50051"
  forceNoTls: true
postgres:
  connection:
    host: localhost
    port: 5432
    user: postgres
    password: psw
    dbname: postgres
    sslmode: disable
leader:
  mode: kubernetes
  leaseLockName: armada-scheduler
  LeaseLockNamespace: "default" # This must be set so viper allows env vars to overwrite it
  leaseDuration: 15s
  renewDeadline: 10s
  retryPeriod: 2s
  podName: "pod-1" # This must be set so viper allows env vars to overwrite it
  leaderConnection:
    armadaUrl: "" # <name> will get replaced with the lease owners name
http:
  port: 8091
grpc:
  port: 50052
  keepaliveParams:
    maxConnectionIdle: 5m
    time: 120s
    timeout: 20s
  keepaliveEnforcementPolicy:
    minTime: 10s
    permitWithoutStream: true
  tls:
    enabled: false
# You may want to configure indexedNodeLabels and indexedTaints to speed up scheduling.
scheduling:
  pools:
    - name: default
  supportedResourceTypes:
    - name: memory
      resolution: "1"
    - name: cpu
      resolution: "1m"
    - name: ephemeral-storage
      resolution: "1"
    - name: nvidia.com/gpu
      resolution: "1"
  disableScheduling: false
  enableAssertions: false
  protectedFractionOfFairShare: 1.0
  nodeIdLabel: "kubernetes.io/hostname"
  priorityClasses:
    armada-default:
      priority: 2000
      preemptible: false
      maximumResourceFractionPerQueue:
        memory: 1.0
        cpu: 1.0
    armada-preemptible:
      priority: 1000
      preemptible: true
  defaultPriorityClassName: "armada-default"
  priorityClassNameOverride: "armada-default"
  maxQueueLookback: 100000
  maximumResourceFractionToSchedule:
    memory: 1.0
    cpu: 1.0
  maximumSchedulingRate: 500.0
  maximumSchedulingBurst: 2500
  maximumPerQueueSchedulingRate: 100.0
  maximumPerQueueSchedulingBurst: 1000
  maxJobSchedulingContextsPerExecutor: 10000
  maxRetries: 3
  dominantResourceFairnessResourcesToConsider:
    - "cpu"
    - "memory"
    - "nvidia.com/gpu"
    - "ephemeral-storage"
  indexedResources:
    - name: "nvidia.com/gpu"
      resolution: "1"
    - name: "cpu"
      resolution: "100m"
    - name: "memory"
      resolution: "100Mi"
    - name: "ephemeral-storage"
      resolution: "1Gi"
  executorTimeout: "10m"
  maxUnacknowledgedJobsPerExecutor: 2500
  executorUpdateFrequency: "60s"


auth:
  basicAuth:
    enableAuthentication: false
  anonymousAuth: true
  permissionGroupMapping:
    submit_any_jobs: ["everyone"]
    create_queue: ["everyone"]
    delete_queue: ["everyone"]
    cancel_any_jobs: ["everyone"]
    reprioritize_any_jobs: ["everyone"]
    watch_all_events: ["everyone"]
    execute_jobs: ["everyone"]
