---
title: Overview
---

import { ArmadaIcon, ArmadaText } from '@/components/logo';

<div className='ms-3 flex flex-col items-center justify-center gap-3 md:my-3'>
  <ArmadaIcon className='w-30 md:w-35' />
  <ArmadaText className='w-30 text-[#00aae1] md:w-35' />
  <div className='flex gap-3'>
    <a href='https://circleci.com/gh/armadaproject/armada' target='_blank'>
      <img
        src='https://circleci.com/gh/helm/helm.svg?style=shield'
        alt='CircleCI'
      />
    </a>
    <a
      href='https://goreportcard.com/report/github.com/armadaproject/armada'
      target='_blank'
    >
      <img
        src='https://goreportcard.com/badge/github.com/armadaproject/armada'
        alt='Go Report Card'
      />
    </a>
    <a
      href='https://artifacthub.io/packages/helm/gresearch/armada'
      title='Go to Artifact Hub'
      target='_blank'
    >
      <img
        src='https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/armada'
        alt='Artifact Hub'
      />
    </a>
    <a
      href='https://insights.lfx.linuxfoundation.org/foundation/cncf/overview?project=armada'
      target='_blank'
      title='Click to view project insights and health checks'
    >
      <img
        src='https://img.shields.io/badge/LFX%20Insights-0094FF'
        alt='LFX Insights Dashboard'
      />
    </a>
  </div>
</div>

Armada is a multi-Kubernetes cluster batch job meta-scheduler designed to handle massive-scale workloads. Built on top of Kubernetes, Armada enables organizations to distribute millions of batch jobs per day across tens of thousands of nodes spanning multiple clusters, making it an ideal solution for high-throughput computational workloads.

## What is Armada?

Armada serves as middleware that transforms Kubernetes into a powerful batch processing platform while maintaining compatibility with service workloads. It addresses the fundamental limitations of running batch workloads at scale on Kubernetes by providing:

- **Multi-cluster orchestration**: Schedule jobs across many Kubernetes clusters seamlessly
- **High-throughput queueing**: Handle millions of queued jobs using specialized storage layers
- **Advanced batch scheduling**: Fair queuing, gang scheduling, preemption, and resource limits
- **Enterprise-grade reliability**: Secure, highly available components designed for production use

As a [CNCF Sandbox project](https://www.cncf.io/), Armada is actively maintained and used in production environments, including at [G-Research](https://www.gresearch.com/) where it processes millions of jobs daily.

## Why Use Armada?

### Kubernetes Limitations for Batch Workloads

Traditional Kubernetes faces several challenges when running batch workloads at scale:

1. **Single Cluster Scaling Limits**: Scaling a single Kubernetes cluster beyond a certain size is [challenging](https://openai.com/blog/scaling-kubernetes-to-7500-nodes/), typically maxing out around 5,000-15,000 nodes depending on configuration.

2. **Storage Backend Constraints**: Achieving very high throughput using etcd, Kubernetes' in-cluster storage backend, is [challenging](https://etcd.io/docs/v3.5/op-guide/performance/) and can become a bottleneck for job queuing.

3. **Inadequate Batch Scheduling**: The default [kube-scheduler](https://kubernetes.io/docs/reference/command-line-tools-reference/kube-scheduler/) lacks essential batch scheduling features like fair queuing, gang scheduling, and intelligent preemption.

### Armada's Solution

Armada overcomes these limitations by:

- **Distributing across multiple clusters**: Manage thousands of nodes across many Kubernetes clusters
- **Out-of-cluster scheduling**: Perform queueing and scheduling using specialized storage layers
- **Purpose-built batch scheduler**: Include advanced scheduling features designed specifically for batch workloads

## Key Features and Benefits

### Core Scheduling Features

**Fair-Use Scheduling**

- Maintains fair resource share over time across users and teams
- Based on dominant resource fairness principles
- Includes priority factors for different queues
- Inspired by HTCondor priority systems

**High Throughput Processing**

- Handle millions of queued jobs simultaneously
- Specialized storage layer optimized for batch workloads
- Efficient job submission and status tracking

**Gang Scheduling**

- Atomically schedule sets of related jobs
- Ensures all jobs in a group start together or not at all
- Critical for distributed computing frameworks like MPI

**Intelligent Preemption**

- Run urgent jobs in a timely fashion
- Balance resource allocation between users
- Configurable preemption policies

### Enterprise-Grade Operations

**Massive Scale Support**

- Utilize multiple Kubernetes clusters simultaneously
- Scale beyond single cluster limitations
- Add and remove clusters without service disruption

**Advanced Resource Management**

- Resource and job scheduling rate limits
- Detailed resource allocation controls
- Node affinity and anti-affinity rules

**Comprehensive Monitoring**

- Detailed analytics via [Prometheus](https://prometheus.io/) integration
- Resource allocation and system behavior insights
- Automatic failure detection and node removal

**Production-Ready Features**

- Secure authentication and authorization
- High availability architecture
- Automatic node failure handling
- Cluster health monitoring

## Core Components

### Queue

Represents a user, team, or project within the system. Queues are used to:

- Maintain fair share allocation over time
- Apply priority factors for different workloads
- Enforce resource limits and quotas
- Provide isolation between different users or teams

### Job

The fundamental unit of work in Armada, described as a Kubernetes PodSpec. Jobs include:

- Resource requirements (CPU, memory, GPU)
- Container specifications and dependencies
- Scheduling constraints and preferences
- Execution parameters and environment variables

### Job Set

A logical grouping of related jobs that enables:

- Observing progress of related jobs together
- Applying policies to groups of jobs
- Coordinating complex workflows
- Tracking dependencies between jobs

## Use Cases and Success Stories

### High-Performance Computing (HPC)

- **Machine Learning Training**: Distribute large-scale ML training jobs across multiple clusters
- **Scientific Computing**: Run complex simulations and data analysis workloads
- **Financial Modeling**: Execute risk calculations and quantitative analysis at scale

### Data Processing Pipelines

- **ETL Workloads**: Process large datasets with parallel batch jobs
- **Data Analytics**: Run distributed analytics jobs across multiple clusters
- **Backup and Archival**: Coordinate large-scale data movement operations

### CI/CD and Development

- **Build Systems**: Distribute compilation and testing jobs
- **Integration Testing**: Run comprehensive test suites across multiple environments
- **Deployment Automation**: Coordinate complex deployment workflows

### Production Deployment at G-Research

G-Research, a leading quantitative research company, uses Armada in production to:

- Process millions of jobs per day
- Manage tens of thousands of nodes
- Support diverse computational workloads
- Maintain high availability and performance

## Comparison with Other Schedulers

### vs. Native Kubernetes Scheduler

- **Scale**: Armada spans multiple clusters vs. single cluster limitation
- **Throughput**: Millions of jobs vs. thousands with native scheduler
- **Batch Features**: Purpose-built for batch vs. service-oriented design
- **Fair Scheduling**: Advanced fair-use policies vs. basic priority classes

### vs. Traditional HPC Schedulers (SLURM, PBS)

- **Container Native**: Built for containerized workloads vs. traditional HPC
- **Kubernetes Integration**: Leverages Kubernetes ecosystem vs. isolated systems
- **Cloud Ready**: Designed for cloud and hybrid environments
- **Modern APIs**: REST/gRPC APIs vs. command-line interfaces

## Getting Started

> [!NOTE]
> TODO: this section will be updated with links to the new documentation structure once it is finalized.

Ready to explore Armada? Here are your next steps:

1. **Quick Start**: Try the [local installation guide](../getting-started/quickstart.md) to get Armada running with Kind
2. **Core Concepts**: Learn about [jobs, queues, and scheduling](../core-concepts/jobs-and-lifecycle.md)
3. **Production Setup**: Review the [operations guide](../operations-guide/installation-and-deployment.md) for production deployment

## Community and Support

> [!NOTE]
> TODO: this section will be updated with links to the new documentation structure once it is finalized.

- **Documentation**: Comprehensive guides and API references
- **Community Slack**: Join discussions on [CNCF Slack](https://cloud-native.slack.com/?redir=%2Farchives%2FC03T9CBCEMC)
- **GitHub**: Report issues and contribute at [github.com/armadaproject/armada](https://github.com/armadaproject/armada)
- **Videos**: Watch [overview presentations](https://www.youtube.com/watch?v=FT8pXYciD9A) and [technical deep-dives](https://www.youtube.com/watch?v=B3WPxw3OUl4)
